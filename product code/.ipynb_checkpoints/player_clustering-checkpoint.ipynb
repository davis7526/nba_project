{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "269c7fe0-9bf1-4692-8ea5-a33e0cad1441",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import nba_api\n",
    "import pandas.io.sql as psql\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFE,f_regression, mutual_info_regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import importnb\n",
    "\n",
    "import import_ipynb\n",
    "from database_interaction import Nba_DB\n",
    "\n",
    "#Try this tomorrow for feature selection\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from yellowbrick.cluster import KElbowVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "925b9049-9ecb-41c3-8fea-1c8ab14d0b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class that manages the clustering algorithm\n",
    "class Clustering_Algorithm:\n",
    "    query = \"\"\n",
    "    n_components = 0\n",
    "    queried_data = pd.DataFrame()\n",
    "    algorithm_data = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, queried_data, n_components = 0):\n",
    "        self.queried_data = queried_data\n",
    "        self.algorithm_data = self.queried_data.copy().drop('player_name', axis = 1)\n",
    "        self.n_components = n_components\n",
    "        #self.get_data()\n",
    "    \n",
    "        \n",
    "    #Execute query and return resulting data\n",
    "    def get_data(self):\n",
    "        try: \n",
    "            db_conn = Nba_DB()\n",
    "            self.queried_data = db_conn.execute_query(self.query)\n",
    "            self.algorithm_data = self.queried_data.copy().drop('player_name', axis = 1)\n",
    "            db_conn.close_connection()\n",
    "        except:\n",
    "            print('Error in trying to connect to DB and Execute Query (Clustering_Algorithm: get_data())')\n",
    "        \n",
    "\n",
    "    \n",
    "    #Start preparing the selected data for the clustering algorithm    \n",
    "    def start_data_prep(self):\n",
    "        #Drop rows with low number of games played (< 5)\n",
    "        try:\n",
    "            self.drop_low_gp()\n",
    "        except:\n",
    "            print('Low GP Drop Failed Clustering_Algorithm: start_data_prep()')\n",
    "            \n",
    "        #Next run label_encoding on the data\n",
    "        try:\n",
    "            self.check_label_encode()\n",
    "        except:\n",
    "            print('Check Label Encode Failed Clustering_Algorithm: start_data_prep()')\n",
    "            \n",
    "        #Next convert any columns that need to be to per game basis\n",
    "        try:\n",
    "            self.check_per_game_conversion()\n",
    "        except:\n",
    "            print('Check Per Game Conversion Failed Clustering_Algorithm: start_data_prep()')\n",
    "        \n",
    "        #Next scale the data       \n",
    "        try:\n",
    "            self.scale_data()\n",
    "        except:\n",
    "            print('Data Scaling Failed Clustering_Algorithm: start_data_prep()')\n",
    "            \n",
    "        #Get PCA components       \n",
    "        try:\n",
    "            self.run_pca()\n",
    "        except:\n",
    "            print('PCA components Clustering_Algorithm: start_data_prep()')\n",
    "            \n",
    "        #Run KElbow Visualizer       \n",
    "        try:\n",
    "            self.run_kelbow()\n",
    "        except:\n",
    "            print('KElbow Failed Clustering_Algorithm: start_data_prep()')\n",
    "        \n",
    "        #Run run_optimal_cluster_scores        \n",
    "        try:\n",
    "            self.run_optimal_cluster_scores()\n",
    "        except:\n",
    "            print('run_optimal_cluster_scores Failed Clustering_Algorithm: start_data_prep()')\n",
    "\n",
    "            \n",
    "        #Run KMeans Clustering       \n",
    "        try:\n",
    "            self.run_k_means()\n",
    "        except:\n",
    "            print('KMEans Failed Clustering_Algorithm: start_data_prep()')\n",
    "        \n",
    "            \n",
    "    #Drop data with less than 5 games played in the season\n",
    "    def drop_low_gp(self):\n",
    "        self.algorithm_data = self.algorithm_data[self.algorithm_data['gp'] > 5]\n",
    "        self.queried_data = self.queried_data[self.queried_data['gp'] > 5]\n",
    "        \n",
    "    #Check each columns data type, and transform to int if necessary\n",
    "    def check_label_encode(self):\n",
    "        for col in self.algorithm_data:\n",
    "            if self.algorithm_data[col].dtype == object:\n",
    "                try:\n",
    "                    self.algorithm_data[col] = self.label_encode(self.algorithm_data[col])\n",
    "                    self.algorithm_data[col] = self.algorithm_data[col].apply(float)\n",
    "                except:\n",
    "                    print('Error in trying to label encode object column (Clustering_Algorithm: label_encode())')\n",
    "                \n",
    "    #Converts object column to label encoding            \n",
    "    def label_encode(self, column):\n",
    "        labelencoder = LabelEncoder()\n",
    "        column = labelencoder.fit_transform(column)\n",
    "        return column\n",
    "    \n",
    "    #Convert stats that aren't on a per game basis to a per game basis\n",
    "    def check_per_game_conversion(self):\n",
    "        #Columns that should be converted to a per game basis\n",
    "        #Need GP column\n",
    "        columns_to_convert = ['fg2m','fg2a', 'fg3m', 'fg3a', 'restricted_area_fgm', 'restricted_area_fga',\n",
    "       'in_the_paint_non_ra_fgm', 'in_the_paint_non_ra_fga','mid_range_fgm', 'mid_range_fga',\n",
    "        'left_corner_3_fgm', 'left_corner_3_fga','right_corner_3_fgm', 'right_corner_3_fga',\n",
    "        'above_the_break_3_fgm','above_the_break_3_fga',  'backcourt_fgm','backcourt_fga', 'corner_3_fgm', 'corner_3_fga',]\n",
    "        \n",
    "        for col in self.algorithm_data:\n",
    "            if col in columns_to_convert:\n",
    "                try:\n",
    "                    self.algorithm_data[col] = self.convert_per_game(self.algorithm_data[col], self.algorithm_data['gp'])\n",
    "                except:\n",
    "                    print('could not convert to per game (Clustering_Algorithm: convert_per_game())')\n",
    "        self.algorithm_data = self.algorithm_data.drop('gp', axis = 1)\n",
    "\n",
    "    \n",
    "    #Convert column to a per game basis to a per game basis\n",
    "    def convert_per_game(self, convert_column, gp_column):\n",
    "        convert_column = convert_column / gp_column\n",
    "        \n",
    "        #Drop the gp data as it should not be included in final dataset\n",
    "        return convert_column\n",
    "\n",
    "    #Scale the data\n",
    "    def scale_data(self):\n",
    "        self.algorithm_data = StandardScaler().fit_transform(self.algorithm_data)\n",
    "        \n",
    "        \n",
    "    #Run a PCA test on the data to identify how many components to use\n",
    "    def run_pca(self):\n",
    "        #Use PCA to reduce the number of features\n",
    "        pca = PCA(n_components = 'mle', svd_solver = 'full')\n",
    "        self.algorithm_data = pca.fit_transform(self.algorithm_data)\n",
    "\n",
    "    #Run KElbow test to figure out number of clusters\n",
    "    def run_kelbow(self):\n",
    "        #Using the elbow method to figure out number of clusters\n",
    "        k_model = KMeans()\n",
    "        elbow_visual = KElbowVisualizer(k_model, k=(5,25))\n",
    "        elbow_visual.fit(self.algorithm_data)\n",
    "        elbow_visual.show()\n",
    "        \n",
    "    #Run sillhouete average scoring to find optimal number of clusters\n",
    "    def run_optimal_cluster_scores(self):\n",
    "        scores_df = pd.DataFrame()\n",
    "        for n_clusters in range(5,30):\n",
    "            clusterer = KMeans(n_clusters=n_clusters, random_state = 1)\n",
    "            preds = clusterer.fit_predict(self.algorithm_data)\n",
    "            centers = clusterer.cluster_centers_\n",
    "\n",
    "            s_score = silhouette_score(self.algorithm_data, preds)\n",
    "            c_score = calinski_harabasz_score(self.algorithm_data, preds)\n",
    "            d_score = davies_bouldin_score(self.algorithm_data, preds)\n",
    "            \n",
    "            cluster_score_dict = {\"n_clusters\": n_clusters,\n",
    "                  \"silhouette_score\": s_score,\n",
    "                  \"calinski_harabasz_score\": c_score,\n",
    "                  \"davies_bouldin_score\": d_score}\n",
    "            #print(cluster_score_dict)\n",
    "            \n",
    "            scores_df = scores_df.append(cluster_score_dict, ignore_index = True)\n",
    "            \n",
    "\n",
    "        scores_df.set_index('n_clusters', inplace = True)\n",
    "        display(scores_df)\n",
    "\n",
    "\n",
    "        #FIGURE OUT HOW TO COME UP WITH AN 'Optimal' number of clusters    \n",
    "        if self.n_components == 0:\n",
    "            self.n_components = int(scores_df['davies_bouldin_score'].idxmax())\n",
    "\n",
    "\n",
    "    #Run the clustering KMeans algorithm\n",
    "    def run_k_means(self):\n",
    "        #Try K-Means clustering\n",
    "        k_means = KMeans(init = 'k-means++', n_clusters = self.n_components)\n",
    "        label = k_means.fit_predict(self.algorithm_data)\n",
    "        \n",
    "        #Getting the Centroids\n",
    "        centroids = k_means.cluster_centers_\n",
    "        u_labels = np.unique(label)\n",
    "        \n",
    "\n",
    "        #plotting the results:\n",
    "        for i in u_labels:\n",
    "            plt.scatter(self.algorithm_data[label == i , 0] , self.algorithm_data[label == i , 1] , label = i)\n",
    "        plt.scatter(centroids[:,0] , centroids[:,1] , s = 80, color = 'k')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        #Add clusters to queried data\n",
    "        self.queried_data['cluster'] = k_means.labels_\n",
    "\n",
    "    #Return the queried data\n",
    "    def get_queried_data(self):\n",
    "        return self.queried_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "76ea1650-c8fd-496a-adbb-674144b26aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"SELECT player_name, e_def_rating, pie, e_off_rating, ast_to, e_pace, e_usg_pct, position, ts_pct, fg2a, fg2_pct, fg3a, fg3_pct, in_the_paint_non_ra_fga ,in_the_paint_non_ra_fg_pct, corner_3_fga, corner_3_fg_pct, gp FROM players where season = '2016-17'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "b6fdbbad-2368-4ea4-b18a-9ee0a85b71c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#cluster = Clustering_Algorithm(query)#, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "4759ce43-771d-4bab-9e28-21cf47d84497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.start_data_prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "09a70b48-10d3-44e3-9e2e-d777dba1ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster.queried_data.loc[cluster.queried_data['cluster'] == 5, ['player_name', 'position', 'cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6125057c-d2ec-4924-8992-3f6913a951ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
